{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Building and Training\n",
    "#### Task 3: Model Training\n",
    "\n",
    "Notebook: notebooks/Model_Training.ipynb\n",
    "Steps:\n",
    "- Choose appropriate features for the model.\n",
    "- Train a linear regression model.\n",
    "- Perform hyperparameter tuning (if applicable).\n",
    "\n",
    "- Script: scripts/train_model.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 201 51 201\n"
     ]
    }
   ],
   "source": [
    "###Load the Preprocessed Dataset\n",
    "def read_file(filename):\n",
    "    filepath = '../Data/'+str(filename)\n",
    "    return pd.read_csv(filepath)\n",
    "\n",
    "X_test = read_file('X_test.csv')\n",
    "y_test = read_file('y_test.csv')\n",
    "X_train = read_file('X_train.csv')\n",
    "y_train = read_file('y_train.csv')\n",
    "\n",
    "print(len(X_test), len(X_train), len(y_test), len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Coefficients: [[ 0.17061797  0.17041086 -0.00658663 -0.23182495  2.47266374 -1.13655857\n",
      "  -1.0625756   0.46516574 -0.74433858 -0.93069212  0.13205168 -0.67872902\n",
      "   0.47862257]]\n",
      "Model Intercept: [22.67517414]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train (fit) the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Print model coefficients\n",
    "print(\"Model Coefficients:\", model.coef_)\n",
    "print(\"Model Intercept:\", model.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Prices: [[22.45519388]\n",
      " [19.3892715 ]\n",
      " [15.39708857]\n",
      " [32.18473759]\n",
      " [19.01763406]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print first five predictions\n",
    "print(\"Predicted Prices:\", y_pred[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 5.044789881350664\n",
      "R-squared Score: 0.7648975829968503\n"
     ]
    }
   ],
   "source": [
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate R-squared (R²) Score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning (Random Forest Rgressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Best Score: 2.5609500786250043\n",
      "Test Set RMSE: 2.1818048668701993\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define Random Forest model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],  # Number of trees\n",
    "    \"max_depth\": [None, 10, 20, 30],  # Maximum depth of trees\n",
    "    \"min_samples_split\": [2, 5, 10],  # Minimum samples to split a node\n",
    "    \"min_samples_leaf\": [1, 2, 4]  # Minimum samples at leaf node\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "rf_grid_search = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1,  # Use all CPU cores\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and best score\n",
    "print(\"Best Parameters:\", rf_grid_search.best_params_)\n",
    "print(\"Best Score:\", np.sqrt(-rf_grid_search.best_score_))  # Convert to RMSE\n",
    "\n",
    "# Evaluate on test set\n",
    "best_rf_model = rf_grid_search.best_estimator_\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "\n",
    "print(\"Test Set RMSE:\", rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning (gradient boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'learning_rate': 0.2, 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200, 'subsample': 0.9}\n",
      "MSE (Gradient Boosting): 5.1362818132835315\n",
      "R² Score (Gradient Boosting): 0.7606337666511536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:44:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"min_samples_leaf\", \"min_samples_split\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the Gradient Boosting model\n",
    "gb = XGBRegressor(random_state=42)\n",
    "\n",
    "# Define hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],  # Number of trees\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1, 0.2],  # Step size shrinkage\n",
    "    \"max_depth\": [3, 4, 5, 6],  # Maximum depth of trees\n",
    "    \"min_samples_split\": [2, 5, 10],  # Minimum samples required to split a node\n",
    "    \"min_samples_leaf\": [1, 3, 5],  # Minimum samples in a leaf node\n",
    "    \"subsample\": [0.7, 0.8, 0.9, 1.0]  # Fraction of samples used per tree\n",
    "}\n",
    "\n",
    "# Using GridSearchCV for exhaustive search\n",
    "gb_grid_search = GridSearchCV(gb, param_grid, scoring=\"neg_mean_squared_error\", cv=5, n_jobs=-1)\n",
    "gb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model and hyperparameters\n",
    "best_gb = gb_grid_search.best_estimator_\n",
    "best_params = gb_grid_search.best_params_\n",
    "\n",
    "# Evaluate the best model\n",
    "y_pred_gb = best_gb.predict(X_test)\n",
    "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
    "r2_gb = r2_score(y_test, y_pred_gb)\n",
    "\n",
    "# Print Results\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"MSE (Gradient Boosting): {mse_gb}\")\n",
    "print(f\"R² Score (Gradient Boosting): {r2_gb}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning (Ridge Rigresson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha: 10\n",
      "MSE (Ridge): 5.124147378088594\n",
      "R² Score (Ridge): 0.7611992844097519\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the Ridge Regression model\n",
    "ridge = Ridge()\n",
    "\n",
    "# Define hyperparameter grid for tuning (alpha values)\n",
    "param_grid = {\"alpha\": [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "# Using GridSearchCV for exhaustive search\n",
    "ridge_grid_search = GridSearchCV(ridge, param_grid, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "ridge_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and model\n",
    "best_ridge = ridge_grid_search.best_estimator_\n",
    "best_alpha = ridge_grid_search.best_params_[\"alpha\"]\n",
    "\n",
    "# Evaluate the best model\n",
    "y_pred_ridge = best_ridge.predict(X_test)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "\n",
    "# Print Results\n",
    "print(f\"Best Alpha: {best_alpha}\")\n",
    "print(f\"MSE (Ridge): {mse_ridge}\")\n",
    "print(f\"R² Score (Ridge): {r2_ridge}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Hyperparameter Tuning(Gradient Boosting Regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Model       MSE        R²  \\\n",
      "1   RandomForest  4.760272  0.778157   \n",
      "0          Ridge  5.124147  0.761199   \n",
      "2  GradientBoost  5.136282  0.760634   \n",
      "\n",
      "                                         Best Params  \n",
      "1  {'max_depth': None, 'min_samples_leaf': 2, 'mi...  \n",
      "0                                      {'alpha': 10}  \n",
      "2  {'learning_rate': 0.2, 'max_depth': 3, 'min_sa...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = {\n",
    "    'Ridge': ridge_grid_search,\n",
    "    'RandomForest': rf_grid_search,\n",
    "    'GradientBoost': gb_grid_search\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'MSE': mean_squared_error(y_test, y_pred),\n",
    "        'R²': r2_score(y_test, y_pred),\n",
    "        'Best Params': model.best_params_\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.sort_values('MSE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved best model to ../data/best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib \n",
    "# Save the best performing model\n",
    "joblib.dump(rf_grid_search, \"../data/best_model.pkl\")\n",
    "print(\"\\nSaved best model to ../data/best_model.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
