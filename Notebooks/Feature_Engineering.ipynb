{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Feature Engineering and Improvement\n",
    "#### Task 5: Feature Engineering\n",
    "\n",
    "Notebook: notebooks/Feature_Engineering.ipynb\n",
    "Steps:\n",
    "- Create new features that might improve model performance.\n",
    "- Test different feature combinations.\n",
    "- Evaluate the impact of new features on model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 201 51 201\n",
      "X_test data: \n",
      "         crim        zn     indus       nox        rm       age       dis  \\\n",
      "0  -0.236041  0.871318 -0.501726 -1.073076  0.439527 -0.440185  1.951028   \n",
      "1  -0.214499  0.237584 -0.144178  0.338419 -0.580839  0.940816  1.253798   \n",
      "2   0.089608 -0.596277  2.349763  1.856155 -0.930475  1.402401 -1.527156   \n",
      "3   2.283708  0.737901 -0.837928  2.205235  2.565886  1.263550 -1.295462   \n",
      "4  -0.332314 -0.596277 -0.823697  0.125936 -1.608341  1.038387 -1.003274   \n",
      "5  -0.558640  2.072078 -0.403890 -0.830238  0.556073 -1.078148 -0.131059   \n",
      "6   1.016799 -0.596277  0.216927  0.641966  0.919980  0.813224 -0.595803   \n",
      "7  -0.626012  2.072078 -1.321774 -1.103430  0.575101 -0.616563  2.496430   \n",
      "8  -0.505262  0.237584 -0.144178  0.338419 -0.854364 -0.819210  0.609211   \n",
      "9  -0.323316 -0.596277 -0.314947 -0.815061 -0.188390 -2.035092  0.761716   \n",
      "10 -0.543046 -0.596277  0.738129 -0.982012 -0.890041 -0.909276  0.073580   \n",
      "11 -0.610532 -0.596277 -0.967784 -0.632932 -0.904312 -1.314569  0.475741   \n",
      "12 -0.736773 -0.596277 -0.620909  0.201823 -0.450023 -0.883006  0.248452   \n",
      "13 -0.470489  1.404989 -0.667159 -1.118608  0.261142 -0.297582  1.504245   \n",
      "14 -0.590172 -0.596277 -0.745428 -0.799883 -0.302557 -0.151226 -0.352869   \n",
      "15  0.709489 -0.596277 -0.441245  0.034872  2.175816  0.715653 -0.653303   \n",
      "16 -0.653922  1.605116 -1.156341 -0.450804  0.874789 -0.102440 -0.566150   \n",
      "17  1.904490 -0.596277 -0.096149  0.550902 -1.239677  0.325370 -0.325248   \n",
      "18  0.125257 -0.596277  2.349763  1.856155 -1.320545  1.319841 -1.459546   \n",
      "19  4.302421 -0.596277 -0.096149  0.550902 -0.419103  1.469950 -0.111459   \n",
      "20  0.142339 -0.596277 -0.021438  0.277710 -0.045682  1.139710 -1.032080   \n",
      "21  2.905839 -0.596277 -0.096149  0.550902 -1.035128  1.469950 -0.156533   \n",
      "22 -0.540759 -0.596277 -0.823697  0.125936 -0.925718  0.295348 -0.943514   \n",
      "23 -0.632265 -0.596277 -1.106533 -0.207966 -0.226446  0.299101 -0.617154   \n",
      "24 -0.209238 -0.596277 -0.314947 -0.815061 -1.346709 -1.014352  0.411237   \n",
      "25  0.241356 -0.596277  0.179572  1.264238 -2.041224  0.452962 -0.888895   \n",
      "26 -0.687817  2.905939 -0.597784 -1.467687  0.158867 -0.571531  1.663358   \n",
      "27 -0.606453 -0.596277 -0.967784 -0.632932  0.201680 -1.637304  0.475741   \n",
      "28  1.538310 -0.596277 -0.096149  0.550902 -0.711655  0.036410  0.189314   \n",
      "29 -0.133325  0.871318 -0.501726 -1.073076 -1.529851  0.351639  2.023552   \n",
      "30 -0.688961 -0.596277  0.926687  0.733030 -0.856742 -0.181248 -0.711820   \n",
      "31 -0.589638 -0.596277  3.018609  1.203529 -0.580839  0.873267 -1.228473   \n",
      "32 -0.562568  2.405622 -0.932207 -0.982012  1.269616 -0.740403 -0.329711   \n",
      "33 -0.357173 -0.596277 -0.021438  0.277710 -0.944746  1.346110 -1.279590   \n",
      "34  0.219700 -0.596277 -0.231342 -0.132079 -1.284868  0.505501  0.196996   \n",
      "35 -0.618158 -0.596277 -0.483938 -0.041015 -0.095630  0.276585 -0.571629   \n",
      "36  0.367330 -0.596277  2.349763  1.856155 -0.728305  1.226023 -1.358667   \n",
      "37  3.836309 -0.596277 -0.096149  0.550902 -0.252609  1.158474 -0.223353   \n",
      "38  0.103944 -0.596277  0.216927  0.641966 -1.292004  0.633093 -0.241371   \n",
      "39 -0.629215  2.072078 -0.403890 -0.830238  1.374269 -1.247020  0.277033   \n",
      "40 -0.665017 -0.596277 -0.745428 -0.799883 -0.554676 -0.590294  0.030992   \n",
      "41  0.097958 -0.596277  0.339668 -0.192789 -1.106483  0.445457 -0.009846   \n",
      "42 -0.510066  1.404989 -0.667159 -1.118608  0.851004 -0.699123  1.026622   \n",
      "43 -0.427214 -0.596277  0.926687  0.733030  0.296819  1.184743 -0.569934   \n",
      "44 -0.442389  1.071445 -0.631582 -0.739174  0.494232  0.261574  1.611563   \n",
      "45 -0.425880  0.737901 -0.306053 -0.572223  0.689267 -0.079924 -0.256904   \n",
      "46  3.909972 -0.596277 -0.096149  0.550902 -1.613098  1.398648 -0.324458   \n",
      "47 -0.644161 -0.596277 -0.745428 -0.799883  0.908087 -0.177495  0.036922   \n",
      "48 -0.440788 -0.596277  0.926687  0.733030 -0.706898  1.237281 -0.837665   \n",
      "49 -0.517196  0.737901 -0.306053 -0.572223 -0.780631  0.025152 -0.256904   \n",
      "50 -0.697464  0.804609 -0.540861 -0.951657 -0.316828  0.081443  1.379530   \n",
      "\n",
      "         rad       tax   ptratio         b     lstat    chas_1  \n",
      "0   1.484407  0.243996  0.358605 -2.474124 -0.268091 -0.260378  \n",
      "1   0.281608 -0.003673 -1.785172 -0.692920  1.404934 -0.260378  \n",
      "2  -0.319792  1.638760  1.512946  0.098231  2.336354 -0.260378  \n",
      "3   0.281608 -0.616326 -2.994482  0.303070  0.113747 -0.260378  \n",
      "4   0.281608 -0.199200 -1.015611  0.819619  0.873009 -0.260378  \n",
      "5  -0.319792 -0.746678 -0.465925  0.819619 -0.782358 -0.260378  \n",
      "6  -0.319792 -0.094919 -0.026176  0.819619 -1.367254 -0.260378  \n",
      "7  -2.123990  0.309172  0.688417  0.819619 -1.049424 -0.260378  \n",
      "8   0.281608 -0.003673 -1.785172 -0.130357  1.098139 -0.260378  \n",
      "9  -0.921191 -1.020416 -0.301019 -1.188688 -1.086946 -0.260378  \n",
      "10  0.281608  1.130388  0.138730  0.694934 -0.360791 -0.260378  \n",
      "11 -0.319792  1.547514 -0.850705 -1.326732 -0.168769 -0.260378  \n",
      "12  0.281608 -1.137733  0.963260  0.706809 -0.491013 -0.260378  \n",
      "13  0.883007 -0.147060 -1.015611 -2.765054  0.107126 -0.260378  \n",
      "14 -0.921191 -0.837924  0.028793  0.559860 -0.506464 -0.260378  \n",
      "15  2.085806 -0.055813 -0.575862 -2.864504 -0.965552 -0.260378  \n",
      "16  1.484407 -1.163803 -0.026176  0.294164 -0.398313 -0.260378  \n",
      "17 -0.319792 -0.055813  1.403009 -0.063561  0.120369 -0.260378  \n",
      "18 -0.319792  1.638760  1.512946  0.108622  1.424798 -0.260378  \n",
      "19 -0.319792 -0.055813  1.403009 -2.174288  0.508828 -0.260378  \n",
      "20  0.281608  0.947895  1.348041 -0.022000  1.062825 -0.260378  \n",
      "21 -0.319792 -0.055813  1.403009  0.469315  2.018523 -0.260378  \n",
      "22  0.281608 -0.199200 -1.015611  0.274867 -0.241605 -0.260378  \n",
      "23 -0.921191 -1.541824 -0.355987 -0.633547  0.533107 -0.260378  \n",
      "24 -0.921191 -1.020416 -0.301019  0.819619 -0.115797 -0.260378  \n",
      "25  0.883007  1.039142  0.413574  0.819619  2.296625 -0.260378  \n",
      "26  0.883007 -0.238306 -1.015611  0.819619 -0.691865 -0.260378  \n",
      "27 -0.319792  1.547514 -0.850705 -2.399907 -0.749251 -0.260378  \n",
      "28 -0.319792 -0.055813  1.403009  0.819619 -0.546192 -0.260378  \n",
      "29  1.484407  0.243996  0.358605 -0.333711  1.705107 -0.260378  \n",
      "30  0.281608 -0.459904 -1.125548  0.211041  0.612565  3.840573  \n",
      "31 -1.522591 -1.606999  0.358605 -2.034760  0.780309 -0.260378  \n",
      "32  0.281608  1.130388 -1.785172  0.369865 -0.894923 -0.260378  \n",
      "33  0.281608  0.947895  1.348041  0.396583  1.265883 -0.260378  \n",
      "34  0.281608 -0.316517  0.633448 -0.036843  0.221898 -0.260378  \n",
      "35  0.281608 -0.420798  0.413574  0.819619 -0.232776 -0.260378  \n",
      "36 -0.319792  1.638760  1.512946 -1.948669  1.360791 -0.260378  \n",
      "37 -0.319792 -0.055813  1.403009  0.819619  1.762493 -0.260378  \n",
      "38 -0.319792 -0.094919 -0.026176  0.748371  0.168926 -0.260378  \n",
      "39 -0.319792 -0.746678 -0.465925  0.307523 -1.451126  3.840573  \n",
      "40 -0.921191 -0.837924  0.028793  0.684544  0.469100 -0.260378  \n",
      "41 -0.319792 -0.446869  0.083762 -0.289181  1.616821 -0.260378  \n",
      "42  0.883007 -0.147060 -1.015611 -1.127831 -0.742629 -0.260378  \n",
      "43  0.281608 -0.459904 -1.125548  0.350568 -0.051789  3.840573  \n",
      "44  2.085806 -0.355622  0.688417  0.819619 -0.883887 -0.260378  \n",
      "45 -0.921191 -1.150768  0.083762  0.531657 -0.663172 -0.260378  \n",
      "46 -0.319792 -0.055813  1.403009 -2.198037  2.270139 -0.260378  \n",
      "47 -0.921191 -0.837924  0.028793  0.136824 -0.928030 -0.260378  \n",
      "48  0.281608 -0.459904 -1.125548  0.819619  1.585921  3.840573  \n",
      "49 -0.921191 -1.150768  0.083762 -0.005672  0.643465  3.840573  \n",
      "50 -0.319792 -0.890065 -0.905674  0.384708 -0.287955 -0.260378  \n",
      "y_test data: \n",
      "     medv\n",
      "0   24.5\n",
      "1   18.9\n",
      "2   13.3\n",
      "3   31.0\n",
      "4   23.1\n",
      "5   29.1\n",
      "6   22.8\n",
      "7   22.9\n",
      "8   21.7\n",
      "9   25.3\n",
      "10  20.3\n",
      "11  19.3\n",
      "12  20.6\n",
      "13  22.2\n",
      "14  22.2\n",
      "15  31.6\n",
      "16  28.4\n",
      "17  18.2\n",
      "18  16.2\n",
      "19  14.5\n",
      "20  19.4\n",
      "21  14.5\n",
      "22  22.6\n",
      "23  29.6\n",
      "24  19.3\n",
      "25  19.7\n",
      "26  22.3\n",
      "27  22.6\n",
      "28  20.4\n",
      "29  18.5\n",
      "30  23.3\n",
      "31  20.3\n",
      "32  32.0\n",
      "33  19.5\n",
      "34  18.5\n",
      "35  18.9\n",
      "36  17.4\n",
      "37  15.2\n",
      "38  16.2\n",
      "39  33.1\n",
      "40  22.5\n",
      "41  22.5\n",
      "42  23.3\n",
      "43  23.0\n",
      "44  22.2\n",
      "45  24.4\n",
      "46  13.6\n",
      "47  26.6\n",
      "48  21.5\n",
      "49  20.7\n",
      "50  20.5\n"
     ]
    }
   ],
   "source": [
    "###Load the Preprocessed Dataset\n",
    "def read_file(filename):\n",
    "    filepath = '../Data/'+str(filename)\n",
    "    return pd.read_csv(filepath)\n",
    "\n",
    "X_test = read_file('X_test.csv')\n",
    "y_test = read_file('y_test.csv')\n",
    "X_train = read_file('X_train.csv')\n",
    "y_train = read_file('y_train.csv')\n",
    "\n",
    "print(len(X_test), len(X_train), len(y_test), len(y_train))\n",
    "\n",
    "print(\"X_test data: \\n\", X_test)\n",
    "print(\"y_test data: \\n\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Create New Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new interaction features\n",
    "X_train['LSTAT_RM'] = X_train['lstat'] * X_train['rm']\n",
    "X_test['LSTAT_RM'] = X_test['lstat'] * X_test['rm']\n",
    "\n",
    "# Add polynomial feature (e.g., squared value)\n",
    "X_train['RM_squared'] = X_train['rm'] ** 2\n",
    "X_test['RM_squared'] = X_test['rm'] ** 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Trained Liner Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Train the model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = lr_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 4.440668506679386\n",
      "R² Score: 0.7930514603017373\n"
     ]
    }
   ],
   "source": [
    "#Evaluate Model\n",
    "print(\"Mean Squared Error (MSE):\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R² Score:\", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/linear_regression_with_features.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the updated dataset with new features\n",
    "import joblib\n",
    "joblib.dump({\n",
    "    'X_train': X_train,\n",
    "    'X_test': X_test,\n",
    "    'y_train': y_train,\n",
    "    'y_test': y_test\n",
    "}, \"../data/engineered_data.pkl\")\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(lr_model, \"../data/linear_regression_with_features.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poly MSE: 1.5391802423963225e+20\n",
      "Poly R²: -7.173043946361264e+18\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# Train with poly features\n",
    "poly_lr = LinearRegression()\n",
    "poly_lr.fit(X_train_poly, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_poly_pred = poly_lr.predict(X_test_poly)\n",
    "print(\"Poly MSE:\", mean_squared_error(y_test, y_poly_pred))\n",
    "print(\"Poly R²:\", r2_score(y_test, y_poly_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/y_polymial_predication.csv']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "joblib.dump(y_poly_pred, \"../data/y_polymial_predication.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
